# Мультимодальне розпізнавання об'єктів за допомогою YOLOv11 та YAMNet

## Розробники

Даний проект розробили студенти Донецького національного університету імені Василя Стуса

Овчар Михайло та Мишківська Яна

## Огляд

У цьому дослідженні ми вивчаємо інтеграцію комп'ютерного зору (YOLO) та розпізнавання на основі звуку (YAMNet) для надійного виявлення об'єктів у мультимодальному середовищі. Проєкт включає реалізацію моделей, попередню обробку даних та оцінку результатів.

## Вимоги

Для запуску проєкту переконайтеся, що у вас встановлено:
- Node.js 18+
- TensorFlow.js

## Встановлення

Клонуйте репозиторій:

```bash
git clone https://github.com/MichailoOvchar/multimodal_object_detection
cd multimodal_object_detection
npm install
```

## Використання

Проєкт розроблений на основі Vite.js з використання камери пристрою (персональної камери для ноутбуків та комп'ютерів і задньої камери для мобільних пристроїв)

### Запуск веб-сторінки

```bash
npm run dev
```

## Набір даних

В якості наборів даних в проєктів використовуються натреновані моделі YOLOv11 та YAMNet, які були скомпільовані у файли необхідні для читання та взаємодії у вебресурсах.

## Результати та оцінка

Продуктивність системи мультимодального розпізнавання оцінюється за допомогою показників точності (precision), повноти (recall) та F1-міри

## Контакти

З питаннями або пропозиціями щодо співпраці звертайтеся за адресою `misha.ovchar23@gmail.com`.
